import logging
from pathlib import Path
from typing import Tuple, Dict
import re
import joblib

logger = logging.getLogger(__name__)

MIN_TEXT_LENGTH = 10

# üéØ –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ï –ü–†–ê–í–ò–õ–ê - —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã

# –°–ª–æ–≤–∞ –∫–æ—Ç–æ—Ä—ã–µ –í–°–ï–ì–î–ê –æ–∑–Ω–∞—á–∞—é—Ç actionable=1
STRONG_ACTIONABLE_KEYWORDS = [
    r'\b(–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω|—Ç–∏–ø–æ–≤–∏–∫|—Ç–∏–ø–æ–≤–∞—è|–∫–æ–ª–ª–æ–∫–≤–∏—É–º|–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω|—ç–∫–∑–∞–º–µ–Ω|–∑–∞—á–µ—Ç|–∫—É—Ä—Å–æ–≤–∞—è|–ø—Ä–∞–∫—Ç–∏–∫|—Å–µ–º–∏–Ω–∞—Ä|–¥–æ—Å–¥–∞—á|—Ä–∞—Å—á–µ—Ç)\b',
]

# –°–ª–æ–≤–∞ –∫–æ—Ç–æ—Ä—ã–µ –í–°–ï–ì–î–ê –æ–∑–Ω–∞—á–∞—é—Ç actionable=0
STRONG_NON_ACTIONABLE_KEYWORDS = [
    r'\b(–æ—Ç–∫—Ä–æ–µ—Ç—Å—è|–æ—Ç–∫—Ä—ã–ª–∏|—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è|–∑–∞–ø–∏—Å—å|–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è|—É–≤–µ–¥–æ–º–ª|–Ω–∞–ø–æ–º–∏–Ω|—Å–ø–∏—Å–æ–∫|–ø–µ—Ä–µ–Ω–æ—Å|–æ—Ç–º–µ–Ω)\b',
]

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ!)
DATE_PATTERNS = [
    r'\d{1,2}[.\-/]\d{1,2}',  # 24.10, 24-10, 24/10
    r'\d{1,2}:\d{1,2}',  # 24:10 (–≤—Ä–µ–º—è)
    r'\d{1,2}\s*(?:—è–Ω–≤|—Ñ–µ–≤|–º–∞—Ä|–∞–ø—Ä|–º–∞–π|–∏—é–Ω|–∏—é–ª|–∞–≤–≥|—Å–µ–Ω|–æ–∫—Ç|–Ω–æ—è|–¥–µ–∫)',  # 24 –æ–∫—Ç—è–±—Ä—è
    r'(?:–∑–∞–≤—Ç—Ä–∞|–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞|—Å–µ–≥–æ–¥–Ω—è)',  # –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
]

# –®—É–º–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–ù–ï actionable)
NOISE_PATTERNS = [
    r'^[–∞-—è—ë]{2,4}$',  # –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
    r'^[–∞—Ö–µ]+$',  # –∞–∞–∞–∞–∞, –µ—Ö–µ—Ö–µ
    r'(—Ö–∞+|—Ö—É+|—Ö–µ+)[\s\.]*$',  # —Å–º–µ—Ö –≤ –∫–æ–Ω—Ü–µ
]


class MLValidator:
    """ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º"""

    def __init__(self, model_dir: str = "models"):
        self.model_dir = Path(model_dir)
        self.model = None
        self.vectorizer = None
        self.is_trained = False

        self.load_model()

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        model_path = self.model_dir / 'model.pkl'
        vectorizer_path = self.model_dir / 'vectorizer.pkl'

        if model_path.exists() and vectorizer_path.exists():
            try:
                self.model = joblib.load(model_path)
                self.vectorizer = joblib.load(vectorizer_path)
                self.is_trained = True
                logger.info(f"‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
                self.is_trained = False
        else:
            logger.error(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {self.model_dir}")
            self.is_trained = False

    def is_noise(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –ª–∏ —Ç–µ–∫—Å—Ç"""
        text_lower = text.lower().strip()

        for pattern in NOISE_PATTERNS:
            if re.search(pattern, text_lower):
                return True

        return False

    def predict(self, text: str) -> Tuple[bool, float, str]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º
        Returns: (should_react, confidence, reason)
        """
        if not self.is_trained:
            return False, 0.0, "ML –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"

        text_lower = text.lower()

        # 1Ô∏è‚É£ –§–ò–õ–¨–¢–†–´
        if len(text.strip()) < MIN_TEXT_LENGTH:
            return False, 0.0, f"–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ ({len(text)} < {MIN_TEXT_LENGTH})"

        if self.is_noise(text):
            return False, 0.0, "–û–±–Ω–∞—Ä—É–∂–µ–Ω —à—É–º (–±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)"

        # 2Ô∏è‚É£ –°–ò–õ–¨–ù–´–ï –ü–†–ê–í–ò–õ–ê - –æ–Ω–∏ –≤–∞–∂–Ω–µ–µ ML

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–ª—å–Ω—ã–µ NON-ACTIONABLE —Å–ª–æ–≤–∞
        for pattern in STRONG_NON_ACTIONABLE_KEYWORDS:
            if re.search(pattern, text_lower):
                logger.debug(f"‚ö†Ô∏è  –°–∏–ª—å–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ NON-ACTIONABLE: {pattern}")
                return False, 0.1, f"–ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤–æ '{pattern}'"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–ª—å–Ω—ã–µ ACTIONABLE —Å–ª–æ–≤–∞ + –¥–∞—Ç–∞
        has_assignment = False
        assignment_found = None
        for pattern in STRONG_ACTIONABLE_KEYWORDS:
            if re.search(pattern, text_lower):
                has_assignment = True
                assignment_found = pattern
                break

        has_date = False
        date_found = None
        for pattern in DATE_PATTERNS:
            match = re.search(pattern, text_lower)
            if match:
                has_date = True
                date_found = match.group(0)
                break

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–¥–∞–Ω–∏–µ + –¥–∞—Ç–∞ = –û–ß–ï–ù–¨ –≤–µ—Ä–æ—è—Ç–Ω–æ actionable
        if has_assignment and has_date:
            logger.debug(f"‚úÖ –°–∏–ª—å–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ ACTIONABLE: –∑–∞–¥–∞–Ω–∏–µ + –¥–∞—Ç–∞")
            return True, 0.95, f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞–Ω–∏–µ + –¥–∞—Ç–∞ ({date_found})"

        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –∑–∞–¥–∞–Ω–∏–µ - –Ω—É–∂–Ω–∞ ML –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        if has_assignment:
            logger.debug(f"üìä –ï—Å—Ç—å –∑–∞–¥–∞–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º ML –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            try:
                X = self.vectorizer.transform([text_lower])
                prediction = self.model.predict(X)[0]
                probabilities = self.model.predict_proba(X)[0]
                confidence = probabilities[1]

                if confidence > 0.6:
                    return True, confidence, "ML –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–æ (–∑–∞–¥–∞–Ω–∏–µ –µ—Å—Ç—å)"
                else:
                    return False, confidence, "ML —Å–æ–º–Ω–µ–≤–∞–µ—Ç—Å—è (–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ)"
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ ML: {e}")
                return True, 0.7, "–û—à–∏–±–∫–∞ ML –Ω–æ –µ—Å—Ç—å –∑–∞–¥–∞–Ω–∏–µ"

        # 3Ô∏è‚É£ –ï–°–õ–ò –ù–ï–¢ –°–ò–õ–¨–ù–´–• –ü–†–ê–í–ò–õ - –∏—Å–ø–æ–ª—å–∑—É–µ–º ML
        try:
            X = self.vectorizer.transform([text_lower])
            prediction = self.model.predict(X)[0]
            probabilities = self.model.predict_proba(X)[0]

            if prediction == 1:
                confidence = probabilities[1]
                reason = f"ML —Ä–µ—à–µ–Ω–∏–µ (confidence: {confidence * 100:.1f}%)"
                return True, confidence, reason
            else:
                confidence = probabilities[0]
                reason = f"ML —Ä–µ—à–µ–Ω–∏–µ (confidence: {confidence * 100:.1f}%)"
                return False, confidence, reason

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ ML: {e}")
            return False, 0.0, f"–û—à–∏–±–∫–∞: {e}"


class MessageValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º"""

    def __init__(self):
        self.ml_validator = MLValidator()

        if not self.ml_validator.is_trained:
            raise RuntimeError("‚ùå ML –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

    def calculate_message_score(self, text: str) -> Tuple[bool, Dict]:
        """–û—Ü–µ–Ω–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        if not text or len(text.strip()) < 2:
            return False, {'error': '–ü—É—Å—Ç–æ–µ', 'confidence': 0.0, 'reason': '–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç'}

        should_react, confidence, reason = self.ml_validator.predict(text)

        score_details = {
            'confidence': confidence,
            'prediction': 'actionable' if should_react else 'non-actionable',
            'reason': reason,
        }

        if should_react:
            logger.info(f"‚úÖ ACTIONABLE ({confidence * 100:.1f}%): {text[:60]} | {reason}")
        else:
            logger.debug(f"‚ùå NON-ACTIONABLE ({confidence * 100:.1f}%): {text[:60]} | {reason}")

        return should_react, score_details

    def should_react(self, text: str) -> bool:
        """–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
        should_react, _ = self.calculate_message_score(text)
        return should_react